import json
import pandas as pd
from transformers import pipeline
import evaluate

# ğŸ”¹ Step 1: Load the JSON file
with open("medical_data.json", "r") as f:
    data = json.load(f)

df = pd.DataFrame(data)
texts = df["src"].tolist()
references = df["tgt"].tolist()

# ğŸ”¹ Step 2: Define models
model_names = [
    "umeshramya/t5_small_medical_512",
    "Falconsai/medical_summarization",
    "facebook/bart-large-cnn"
]

# ğŸ”¹ Step 3: Define evaluation function
def evaluate_all(preds, references, sources):
    results = {}

    # ROUGE
    rouge = evaluate.load("rouge")
    rouge_scores = rouge.compute(predictions=preds, references=references)
    results["rougeL"] = rouge_scores["rougeL"]

    # BERTScore
    bertscore = evaluate.load("bertscore")
    berts = bertscore.compute(predictions=preds, references=references, lang="en")
    results["bertscore_f1"] = sum(berts["f1"]) / len(berts["f1"])

    # QuestEval (Optional: Handle failure)
    try:
        questeval = evaluate.load("questeval")
        quest = questeval.compute(predictions=preds, sources=sources)
        results["questeval_score"] = quest["score"]
    except Exception as e:
        results["questeval_score"] = None
        print("QuestEval failed:", str(e))

    return results

# ğŸ”¹ Step 4: Summarization + Evaluation
all_results = []

for model_name in model_names:
    print(f"\nğŸ”„ Running model: {model_name}")
    summarizer = pipeline("summarization", model=model_name)

    summaries = summarizer(texts[:100], max_length=64, min_length=10, truncation=True)
    preds = [s["summary_text"] for s in summaries]

    metrics = evaluate_all(preds, references[:100], texts[:100])
    metrics["model"] = model_name
    all_results.append(metrics)

# ğŸ”¹ Step 5: Compare and find best model
result_df = pd.DataFrame(all_results)
result_df_sorted = result_df.sort_values(by=["rougeL", "bertscore_f1"], ascending=False)

print("\nğŸ“ˆ Evaluation Results:")
print(result_df_sorted)

best_model = result_df_sorted.iloc[0]["model"]
print(f"\nğŸ† Best Model Based on ROUGE & BERTScore: {best_model}")
