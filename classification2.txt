# Full Pipeline with Hyperparameter Tuning for All Models
import pandas as pd
import numpy as np
import re
import shap
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import f1_score, classification_report, confusion_matrix

# ---------------------------
# Load and Preprocess Data
# ---------------------------
df = pd.read_csv("mental_health.csv")
df['Text'] = df['Text'].astype(str)
df['Label'] = df['Label'].astype(str).str.strip()

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'<.*?>+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df['clean_text'] = df['Text'].apply(clean_text)

label_encoder = LabelEncoder()
df['encoded_label'] = label_encoder.fit_transform(df['Label'])

X_train, X_test, y_train, y_test = train_test_split(
    df['clean_text'], df['encoded_label'],
    test_size=0.2, stratify=df['encoded_label'], random_state=42
)

tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english')
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# ---------------------------
# Model Definitions with GridSearch
# ---------------------------
model_params = {
    "Logistic Regression": {
        'model': LogisticRegression(max_iter=1000),
        'params': {
            'C': [0.01, 0.1, 1, 10],
            'solver': ['liblinear', 'lbfgs']
        }
    },
    "Naive Bayes": {
        'model': MultinomialNB(),
        'params': {
            'alpha': [0.5, 1.0, 1.5]
        }
    },
    "SVM": {
        'model': LinearSVC(),
        'params': {
            'C': [0.01, 0.1, 1, 10]
        }
    },
    "Random Forest": {
        'model': RandomForestClassifier(random_state=42),
        'params': {
            'n_estimators': [100, 200],
            'max_depth': [None, 10, 20]
        }
    },
    "XGBoost": {
        'model': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),
        'params': {
            'n_estimators': [100, 200],
            'max_depth': [3, 5],
            'learning_rate': [0.05, 0.1]
        }
    }
}

f1_scores = {}
model_instances = {}

for name, mp in model_params.items():
    print(f"\nüîç Tuning {name}...")
    grid = GridSearchCV(mp['model'], mp['params'], cv=3, scoring='f1_macro', n_jobs=-1)
    grid.fit(X_train_tfidf, y_train)
    best_model = grid.best_estimator_
    y_pred = best_model.predict(X_test_tfidf)
    f1 = f1_score(y_test, y_pred, average='macro')
    f1_scores[name] = f1
    model_instances[name] = best_model

    print(f"\n=== {name} ===")
    print("Best Params:", grid.best_params_)
    print("F1 Score:", f1)
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title(f"Confusion Matrix - {name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

# ---------------------------
# Select Best Model
# ---------------------------
best_model_name = max(f1_scores, key=f1_scores.get)
best_model = model_instances[best_model_name]
print(f"\n\n‚úÖ Best Model: {best_model_name} (F1 = {f1_scores[best_model_name]:.4f})")

# ---------------------------
# SHAP Visualization
# ---------------------------
sample_idx = 5
sample_text = X_test.iloc[sample_idx]
sample_vector = X_test_tfidf[sample_idx]

print(f"\nüß† Text Sample: {sample_text}")
print(f"üìå True Label: {label_encoder.inverse_transform([y_test.iloc[sample_idx]])[0]}")
print(f"üîÆ Predicted: {label_encoder.inverse_transform([best_model.predict(sample_vector)])[0]}")

X_explain = X_test_tfidf[:100]
feature_names = tfidf.get_feature_names_out()

try:
    if best_model_name in ["Logistic Regression", "Naive Bayes"]:
        explainer = shap.Explainer(best_model, X_train_tfidf, feature_names=feature_names)
        shap_values = explainer(sample_vector)
        shap.plots.text(shap_values)

    elif best_model_name == "Random Forest" or best_model_name == "XGBoost":
        explainer = shap.TreeExplainer(best_model)
        shap_values = explainer.shap_values(X_explain)
        shap.summary_plot(shap_values, X_explain, feature_names=feature_names)

    elif best_model_name == "SVM":
        calibrated = CalibratedClassifierCV(best_model, method='sigmoid')
        calibrated.fit(X_train_tfidf, y_train)
        explainer = shap.KernelExplainer(calibrated.predict_proba, X_train_tfidf[:50])
        shap_values = explainer.shap_values(sample_vector, nsamples=100)
        shap.summary_plot(shap_values, feature_names=feature_names)

    else:
        print("‚ö†Ô∏è SHAP explainer not implemented for this model.")

except Exception as e:
    print("‚ö†Ô∏è SHAP explanation failed:", e)
