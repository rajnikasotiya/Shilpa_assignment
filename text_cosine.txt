import pandas as pd
import re
from sentence_transformers import SentenceTransformer, util
import numpy as np

# === Load CSV ===
df = pd.read_csv("results.csv")

# === Categories & aliases ===
CATEGORY_ALIASES = {
    "Visit Reason": ["Visit Reason", "Reason for Visit", "Chief Complaint"],
    "Diagnosis": ["Diagnosis", "Final Diagnosis", "Provisional Diagnosis"],
    "Past Medical History": ["Past Medical History", "PMH", "History of Illness"],
    "Clinical Details": ["Clinical Details", "Clinical Notes", "Case Details"],
    "Vital Signs": ["Vital Signs", "Vitals", "Patient Vitals"],
    "Exam Results": ["Exam Results", "Physical Examination", "Exam Findings"],
    "Lab Results": ["Lab Results", "Laboratory Findings", "Labs"],
    "Imaging Test Results": ["Imaging Test Results", "Radiology", "Imaging Results"],
    "Hospital and ED course": ["Hospital and ED course", "ED Course", "Hospital Course"],
    "Discharge Plan": ["Discharge Plan", "Plan at Discharge", "Discharge Instructions"],
    "Full HPI": ["Full HPI", "History of Present Illness", "HPI"],
    "Full Assessment and Plan": ["Full Assessment and Plan", "Assessment and Plan", "Plan"]
}

CATEGORIES = list(CATEGORY_ALIASES.keys())

# === Load embedding model ===
embedder = SentenceTransformer("all-MiniLM-L6-v2")

def extract_with_best_similarity(text, threshold=0.65, top_k=3):
    """
    Extract info for each category with heading match (fuzzy via aliases) 
    and fallback to top-N cosine similarity matches.
    """
    text = str(text).strip()
    result = {cat: [] for cat in CATEGORIES}
    similarity_scores = {cat: 0.0 for cat in CATEGORIES}
    
    # === Heading-based extraction (fuzzy match via aliases) ===
    for cat, aliases in CATEGORY_ALIASES.items():
        found_match = False
        for alias in aliases:
            pattern = rf"(?i){re.escape(alias)}\s*[:\-]?\s*(.*?)(?=\n[A-Z].*[:\-]|\Z)"
            match = re.search(pattern, text, re.S)
            if match:
                value = match.group(1).strip()
                if value:
                    extracted = [v.strip() for v in value.split("\n") if v.strip()]
                    # Add extra sentence if available
                    lines = text.split("\n")
                    for i, line in enumerate(lines):
                        if alias.lower() in line.lower() and i + 1 < len(lines):
                            extracted.append(lines[i + 1].strip())
                            break
                    result[cat] = extracted
                    similarity_scores[cat] = 1.0
                    found_match = True
                    break
        if found_match:
            continue
    
    # === Fallback: cosine similarity (top-N paragraphs) ===
    paragraphs = [p.strip() for p in text.split("\n") if p.strip()]
    if paragraphs:
        para_embeddings = embedder.encode(paragraphs, convert_to_tensor=True)
        
        for cat in CATEGORIES:
            if not result[cat]:  # no heading match
                cat_embedding = embedder.encode(cat, convert_to_tensor=True)
                cosine_scores = util.cos_sim(cat_embedding, para_embeddings)[0]
                
                top_indices = np.argsort(cosine_scores.cpu().numpy())[::-1][:top_k]
                top_matches = [
                    paragraphs[idx]
                    for idx in top_indices
                    if float(cosine_scores[idx]) >= threshold
                ]
                
                if top_matches:
                    result[cat] = top_matches
                    similarity_scores[cat] = max(float(cosine_scores[idx]) for idx in top_indices)
    
    return result, similarity_scores

def cosine_similarity_between_columns(context_text, compare_text, threshold=0.65, top_k=3):
    """
    Compute cosine similarity between context column text and compare_text (like GPT-4 output).
    """
    context_text = str(context_text).strip()
    compare_text = str(compare_text).strip()
    
    result = {cat: [] for cat in CATEGORIES}
    scores = {cat: 0.0 for cat in CATEGORIES}
    
    if not compare_text:
        return result, scores
    
    context_paragraphs = [p.strip() for p in context_text.split("\n") if p.strip()]
    compare_paragraphs = [p.strip() for p in compare_text.split("\n") if p.strip()]
    
    if not context_paragraphs or not compare_paragraphs:
        return result, scores
    
    context_embeddings = embedder.encode(context_paragraphs, convert_to_tensor=True)
    compare_embeddings = embedder.encode(compare_paragraphs, convert_to_tensor=True)
    
    for cat in CATEGORIES:
        cat_embedding = embedder.encode(cat, convert_to_tensor=True)
        cosine_scores = util.cos_sim(cat_embedding, compare_embeddings)[0]
        
        top_indices = np.argsort(cosine_scores.cpu().numpy())[::-1][:top_k]
        top_matches = [
            compare_paragraphs[idx]
            for idx in top_indices
            if float(cosine_scores[idx]) >= threshold
        ]
        
        if top_matches:
            result[cat] = top_matches
            scores[cat] = max(float(cosine_scores[idx]) for idx in top_indices)
    
    return result, scores

# === Apply extraction for context column ===
MODEL_NAME = "distilbert-base-uncased"
df_results = []
df_scores = []
avg_scores = []

# === Apply cosine similarity for GPT-4 column (vs context) ===
gpt4_results = []
gpt4_scores = []
gpt4_avg_scores = []

for idx, row in df.iterrows():
    extracted, scores = extract_with_best_similarity(row["context"])
    df_results.append(extracted)
    df_scores.append(scores)
    avg_scores.append(np.mean(list(scores.values())) if scores else 0.0)
    
    gpt4_extracted, gpt4_sim_scores = cosine_similarity_between_columns(row["context"], row.get("gpt4", ""))
    gpt4_results.append(gpt4_extracted)
    gpt4_scores.append(gpt4_sim_scores)
    gpt4_avg_scores.append(np.mean(list(gpt4_sim_scores.values())) if gpt4_sim_scores else 0.0)

# === Save results back to DataFrame ===
df[MODEL_NAME] = df_results
df["cosine_similarity_scores"] = df_scores
df["average_cosine_similarity"] = avg_scores

df["gpt4_cosine_similarity"] = gpt4_scores
df["gpt4_average_cosine_similarity"] = gpt4_avg_scores

# === Save CSV ===
df.to_csv("results_with_best_cosine_similarity.csv", index=False)
print("Extraction + cosine similarity for context and GPT-4 completed and saved.")
