!pip install --upgrade transformers accelerate safetensors pandas --quiet

import pandas as pd
import json
import re
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

# -------------------
# CONFIG
# -------------------
model_name = "microsoft/Phi-2"
output_col = model_name.replace("/", "_")  # => "microsoft_Phi_2"
batch_size = 100
max_new_tokens = 200
temperature = 0.0

# -------------------
# LOAD MODEL & TOKENIZER
# -------------------
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="cpu",
    torch_dtype="auto",
    trust_remote_code=True
)

pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer
)

# -------------------
# PROMPT TEMPLATE
# -------------------
def build_prompt(text):
    return f"""
Extract the following from the medical note in valid JSON format:
- visit_reason
- diagnosis
- past_medical_history
- vital_signs
- exam_results
- lab_results
- full_HPI
- discharge_plan

Return ONLY JSON, no extra text.

Medical Note:
{text}
"""

# -------------------
# EXTRACTION FUNCTION (BATCH)
# -------------------
def extract_medical_info_batch(texts):
    results = []
    for text in texts:
        prompt = build_prompt(text)
        resp = pipe(prompt, max_new_tokens=max_new_tokens, temperature=temperature, do_sample=False)[0]['generated_text']

        # Extract JSON only
        match = re.search(r"\{.*\}", resp, re.DOTALL)
        if match:
            try:
                parsed = json.loads(match.group(0))
                combined = " | ".join([f"{k}: {v}" for k, v in parsed.items()])
                results.append(combined)
                continue
            except json.JSONDecodeError:
                pass
        results.append("")  # fallback if parsing fails
    return results

# -------------------
# READ DATA
# -------------------
df = pd.read_csv("result.csv")

# -------------------
# PROCESS IN BATCHES
# -------------------
all_results = []
for i in range(0, len(df), batch_size):
    batch_texts = df["context"].iloc[i:i+batch_size].tolist()
    batch_results = extract_medical_info_batch(batch_texts)
    all_results.extend(batch_results)

df[output_col] = all_results

# -------------------
# SAVE
# -------------------
df.to_csv("result_with_extractions.csv", index=False)
print(f"âœ… Extraction complete. Saved to result_with_extractions.csv with column '{output_col}'.")
