import pandas as pd
import duckdb
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# ==========================
# 1. Load CSV file
# ==========================
CSV_PATH = "claims_data.csv"   #  change this to your file path
df = pd.read_csv(CSV_PATH)

print("CSV Loaded. Shape:", df.shape)
print("Columns:", df.columns.tolist()[:10], "...")  # show first 10 columns

# ==========================
# 2. Load Text-to-SQL Model
# ==========================
MODEL_NAME = "mrm8488/t5-base-finetuned-wikiSQL"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)

def text_to_sql(question: str, schema: str = "") -> str:
    """
    Converts a natural language question into an SQL query.
    """
    input_text = f"translate English to SQL: {question} {schema}"
    inputs = tokenizer.encode(input_text, return_tensors="pt", max_length=512, truncation=True)
    outputs = model.generate(inputs, max_length=256, num_beams=4, early_stopping=True)
    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return sql_query

# ==========================
# 3. Build Schema from CSV
# ==========================
schema_info = f"Table: claims_data, Columns: {', '.join(df.columns)}"

# ==========================
# 4. Interactive Loop
# ==========================
duckdb.register("claims_data", df)

print("\nAsk me anything about your data! (type 'exit' to quit)\n")

while True:
    question = input("Enter your question: ")
    if question.lower() in ["exit", "quit", "q"]:
        print(" Exiting. Goodbye!")
        break

    # Generate SQL from question
    sql_query = text_to_sql(question, schema_info)
    print("\nGenerated SQL:\n", sql_query)

    # Try running SQL
    try:
        result = duckdb.query(sql_query).to_df()
        print("\nQuery Result:")
        print(result.head(10))  # show top 10 rows only
    except Exception as e:
        print("\nSQL Execution Failed:", e)

    print("\n" + "="*60 + "\n")
